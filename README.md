# **TierSense: File Access Pattern to Tiering Advisor (LLM-Powered)**

---
<p align="center">
<img src="https://github.com/user-attachments/assets/ef229501-4a49-48b2-b06d-cee521be674a" alt="TierSense Logo" width="400" height="370"/>
</p>

*TierSense is an intelligent, LLM-powered advisor that helps optimize file storage across hot, warm, and cold tiers based on real-time access patterns. Think of it as a brain for your storage systemsâ€”analyzing file access logs and recommending exactly which files should live where.*
 
---
 
## ğŸ“Œ Project Overview
 
TierSense transforms noisy file access logs into meaningful **tiering decisions**.
 
## ğŸ§ª Tech Stack
 
- **Python** (Data pipeline, heatmap, LLM integration)
- **Filebeat** (Log shipping and monitoring)
- **Matplotlib / Pandas** (Heatmap generation)
- **Gemini/OpenAI GPT** (LLM-based recommendations)
- **Bash/CLI Tools** (Visualization and automation)
 
---
 
## ğŸš€ Features
 
- **Real-time file access simulation and logging**
- **Real-time audit log analysis via Filebeat**
- **File access pattern classification (hot/warm/cold)**
- **Heatmap generation to identify hot and cold files**
- **Visual output with heatmap**
- **LLM-driven tiering advice**
- **Multiple LLM-powered advisory engines (OpenAI/Gemini/Claude/Llama/Deepseek)**
- **Cloud tier recommendation**
- **Easy integration into storage lifecycle and archive tools**
- **Full Dockerized deployment (NFS + Frontend + Backend)**

---

## ğŸ“ Project Structure
```
TierSense/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

---

## ğŸ”„ Project Pipeline

<img width="2534" height="717" alt="image" src="https://github.com/user-attachments/assets/d9e873b3-6002-4b7b-8f41-d7db880f3e4d" />


---

## ğŸ§  Architecture Diagram
```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   VM1 (NFS)  â”‚
                    â”‚              â”‚
                    â”‚  /nfs/logs   â”‚â—„â”€â”€â”€ Filebeat Output
                    â”‚              â”‚
                    â””â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚   (NFS Mount)
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   Mounts NFS   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   VM2        â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Docker Containers â”‚
â”‚              â”‚               â”‚                   â”‚
â”‚ /var/log/... â”‚               â”‚ - Backend (FastAPI)
â”‚              â”‚               â”‚ - Frontend(nextjs)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”˜
```

---

## ğŸ› ï¸ How to Use

### 1ï¸âƒ£ Basic Setup Instructions

#### ğŸ”§ Step 1: Set up two VMs
- **VM1 (Filebeat + NFS Server):**
  - Runs Filebeat to capture logs
  - Hosts parsed logs in `/nfs/logs`

- **VM2 (App Host):**
  - Hosts **Frontend** and **Backend** containers
  - Mounts `/nfs/logs` from VM1 at `/var/log/sharedlogs`

#### ğŸªµ Filebeat Setup (on VM1)
- Already configured via `basic-setup.sh`
- Ensure it exports logs in `.ndjson` format to `/nfs/logs/`

#### ğŸ“¦ NFS Server Setup (on VM1)
```bash
#!/bin/bash

set -e

# Configuration
EXPORT_DIR="/nfs/logs"
EXPORT_CLIENT="*" # You can set to specific IP or CIDR like 192.168.1.0/24

echo "ğŸ›  Installing NFS server..."
sudo apt update
sudo apt install -y nfs-kernel-server

echo "ğŸ“ Creating export directory at $EXPORT_DIR..."
sudo mkdir -p "$EXPORT_DIR"
sudo chown nobody:nogroup "$EXPORT_DIR"
sudo chmod 777 "$EXPORT_DIR"  # Adjust permissions as needed

echo "ğŸ”§ Configuring /etc/exports..."
EXPORT_ENTRY="$EXPORT_DIR $EXPORT_CLIENT(rw,sync,no_subtree_check,no_root_squash)"
grep -qxF "$EXPORT_ENTRY" /etc/exports || echo "$EXPORT_ENTRY" | sudo tee -a /etc/exports

echo "ğŸ“¤ Exporting NFS shares..."
sudo exportfs -a

echo "ğŸ” Restarting NFS server..."
sudo systemctl restart nfs-kernel-server

echo "âœ… NFS server setup complete!"
echo "ğŸ“¦ Exported directory: $EXPORT_DIR"
echo "ğŸŒ Accessible from: $EXPORT_CLIENT"
```

#### ğŸ”„ Make mount persistent on VM2
```bash
# One-time mount
sudo mount <VM1-IP>:/nfs/logs /var/log/sharedlogs

# Make it persistent
sudo bash -c 'echo "<VM1-IP>:/nfs/logs /var/log/sharedlogs nfs defaults 0 0" >> /etc/fstab'
```
Replace `<VM1-IP>` with the actual IP address of your VM1 (NFS host).

### 2ï¸âƒ£ Audit Rules Setup
```bash
sudo auditctl -w /mnt/data -p war -k access_monitor
```

### 3ï¸âƒ£ Docker Support Setup

#### ğŸ“¦ docker-compose.yml
```yaml
version: '3.9'
services:
  backend:
    build:
      context: ./backend
    ports:
      - "8000:8000"
    volumes:
      - /var/log/sharedlogs:/var/log/sharedlogs

  frontend:
    build:
      context: ./frontend
    ports:
      - "3000:3000"
```

#### ğŸ”¥ Build and Run All at Once
```bash
docker compose build --no-cache
docker compose up
```
> Make sure VM2 has the NFS mount `/var/log/sharedlogs` pointing to VM1's `/nfs/logs`

---

## ğŸ’¼ Business Use Cases

  - Reduce storage costs by demoting cold files to cheap media
  - Increase SSD utilization for high-performance files
  - Automate file lifecycle decisions
  - Plug into hybrid storage, cloud archiving, and NAS systems
 
---

## âœ¨ Challenges We Solved

  - Handling high-velocity file access logs in near real-time
  - Converting raw JSON into visual and AI-friendly format
  - Integrating with Gemini API to offload decision-making to LLMs
  - Making everything scriptable and automatable
    
## ğŸ“¬ Contact
For any issues or enhancements, feel free to raise a GitHub issue or pull request. Happy tiering!
